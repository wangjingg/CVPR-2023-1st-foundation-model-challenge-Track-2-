{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVPR 2023第一届大模型比赛Track2 第1名方案\n",
    "\n",
    "### 一、赛题背景\n",
    "交通场景中高性能的图像检索能力对于交通执法、治安治理具有十分重要的作用，传统的图像检索方式通常使用先对图像进行属性识别再通过与期望属性的对比实现检索能力。随着多模态大模型技术的发展，文本与图像的表征统一和模态转换已有广泛应用，使用该能力可以进一步提升图像检索的精度和灵活性。\n",
    "### 二、赛题任务\n",
    "本赛道旨在提升交通场景中文本图像检索的精度。因此我们将多种公开数据集以及网络数据中的交通参与者图像进行了文本描述标注从而构建了多对多的图像-文本对，选手可以在此基础上进行多模态技术的研究工作，提升文本检索图像的精度。\n",
    "### 三、数据集介绍\n",
    "本赛题构建了一个多交通参与者的文本检索图像数据集，该数据集以开源数据集为基础，同时使用网络爬虫技术扩充数据的丰富度。在标注方面，首先利用CV大模型丰富图像标注属性，然后利用大语言模型构造图像对应的文本标注。目前数据集的总量有153728张，其中训练集136117张，评测集17611张。数据集包含行人和车辆2类交通参与者，数据分布具体见下表。\n",
    "|  类别   | 训练集  | 测试集 |\n",
    "|  ----  | ----  | ---- |\n",
    "| 行人  | 90000 | 10000 |\n",
    "| 车辆  | 46117 | 7611 |\n",
    "| 总数  | 136117 | 17611 |\n",
    "\n",
    "### 四、流程简介\n",
    "基于open_clip与blip工程，使用私有数据在开源预训练模型基础上微调，在A榜数据集上再次微调。然后找出在A榜测试集精度较高的的模型，最终融合clip和blip结果。\n",
    "\n",
    "### 五、任务分析\n",
    "1.训练集与测试集车辆图像分布差异较大，凸显灾难性遗忘问题，导致在验证集上精度提升策略对测试集无效甚至降低，采用降低学习率，降低迭代次数缓解此问题，只微调2-3个epoch。\\\n",
    "2.训练集噪声数据较多，使用截断loss较大值策略缓解此问题。\\\n",
    "3.中文车辆品牌分词问题，例如BYD，分成BYD，其语义已经完全改变。采用prompt argumentation缓解此问题。\\\n",
    "4.车辆，行人图像比例差异大，采用最大边padding缓解此问题。\n",
    "\n",
    "\n",
    "### 六、数据处理\n",
    "#### padding：\n",
    "等比缩放最大边224,短边用零像素padding。\n",
    "#### prompt增强：\n",
    " ##### 车辆prompt增强方式：\n",
    "  从颜色、品牌、车型三个维度进行增强,添加prompt.\\\n",
    "  color_prompt = The color of the vehicle is\\\n",
    "  brand_prompt = The brand of the vehicle is\\\n",
    "  type_prompt = The vehicle's model is\\\n",
    "  text = 原始txt + This is a vehicle + brand_prompt + type_prompt + color_prompt\n",
    " ##### 行人prompt增强方式：\n",
    "#### 图像数据增强：\n",
    "训练集使用RandomAugment，['Identity','AutoContrast','Brightness','Sharpness','Equalize','ShearX', 'ShearY', 'TranslateX', 'TranslateY']\n",
    "\n",
    "\n",
    "### 七、模型设计\n",
    "使用clip和blip作为基本模型进行优化与融合，模型融合遵循的原则是采用尽可能差异大的模型结构和训练策略\\\n",
    "代码主要基于blip和clip\\\n",
    "源码地址：https://github.com/salesforce/BLIP  &&  https://github.com/mlfoundations/open_clip\n",
    "#### BLIP\n",
    "采用BLIP-large版本，训练ita+itm\n",
    "#### CLIP\n",
    "采用两个不同训练策略的ViT-H-14和xlm-roberta-large-ViT-H-14进行训练\n",
    "\n",
    "#### 涨点策略\n",
    "1.数据集padding\\\n",
    "2.prompt增强\\\n",
    "3.数据增强\\\n",
    "4.噪声loss截断\\\n",
    "5.少部分层微调\n",
    "6.异构模型融合，以及合理的归一化策略\n",
    "7.TOP10内二次排序\n",
    "\n",
    "### 八、训练细节\n",
    "#### 预训练阶段\n",
    "预训练阶段使用开源，私有车辆行人类型数据以及stable-difusion生成行人数据组成。\n",
    "#### 微调阶段\n",
    "由于训练集和测试集车辆分布差异较大，为了降低灾难性遗忘和过拟合，采用较低的学习率和迭代次数。\n",
    "\n",
    "### 八、模型融合\n",
    "融合模型：BLIP-large + CLIP-H×3 共四个模型。\\\n",
    "将BLIP ita输出与三个CLIP相似度输出融合，将融合后相似度top10输入BLIP itm头，利用BLIP itm头对top10进行重排序得到最终的相似度。\n",
    "\n",
    "### 九、注意事项\n",
    "1.由于存储不够，在训练之前请使用rm -r /home/aistudio/data/data218773 将A榜提交的checkpoint删除（重启会自动恢复）\n",
    "2.本工程基于V100 32GB *4，如果出现显存不够，可以尝试降低batch size，或者将amp修改为bf16或者fp16等\n",
    "3.ai studio和本地每个模型结果有稍许不同，所以融合之后精度与提交结果可能存在稍许差异，可能原因是本地训练clip与blip为两\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-19T09:40:48.903509Z",
     "iopub.status.busy": "2023-05-19T09:40:48.902878Z",
     "iopub.status.idle": "2023-05-19T09:41:26.930935Z",
     "shell.execute_reply": "2023-05-19T09:41:26.929664Z",
     "shell.execute_reply.started": "2023-05-19T09:40:48.903469Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data218656  data218773\r\n",
      "2023_04_24-11_05_06-model_ViT-H-14-epoch_2.pt\r\n",
      "annots.tar\r\n",
      "blip_model_large.pth\r\n",
      "blip_pretrained.pth\r\n",
      "models--xlm-roberta-large.tar\r\n",
      "model_xlm-roberta-large-ViT-H-14-epoch_2.pt\r\n",
      "test.tar\r\n",
      "train.tar\r\n",
      "val.tar\r\n",
      "/home/aistudio/data/data218656\r\n",
      "2023_04_24-11_05_06-model_ViT-H-14-epoch_2.pt\r\n",
      "annots\r\n",
      "annots.tar\r\n",
      "blip_model_large.pth\r\n",
      "blip_pretrained.pth\r\n",
      "models--xlm-roberta-large\r\n",
      "models--xlm-roberta-large.tar\r\n",
      "model_xlm-roberta-large-ViT-H-14-epoch_2.pt\r\n",
      "test\r\n",
      "test.tar\r\n",
      "train\r\n",
      "train.tar\r\n",
      "val\r\n",
      "val.tar\r\n",
      "/home/aistudio/.cache\r\n",
      "/home/aistudio/.cache/huggingface\r\n"
     ]
    }
   ],
   "source": [
    "# 基于V100 32GB *4\n",
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data\n",
    "!ls /home/aistudio/data/data218656\n",
    "# 解压数据\n",
    "!cd /home/aistudio/data/data218656 && pwd && tar xf train.tar && tar xf val.tar && tar xf test.tar && tar xf annots.tar && tar xf models--xlm-roberta-large.tar\n",
    "!ls /home/aistudio/data/data218656\n",
    "\n",
    "!cd /home/aistudio/.cache/ && pwd && mkdir huggingface\n",
    "!cd /home/aistudio/.cache/huggingface && pwd && mkdir  hub\n",
    "!cp -r /home/aistudio/data/data218656/models--xlm-roberta-large /home/aistudio/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-19T09:56:24.188201Z",
     "iopub.status.busy": "2023-05-19T09:56:24.187551Z",
     "iopub.status.idle": "2023-05-19T09:57:12.439730Z",
     "shell.execute_reply": "2023-05-19T09:57:12.438599Z",
     "shell.execute_reply.started": "2023-05-19T09:56:24.188160Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: timm==0.4.12 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (0.4.12)\r\n",
      "Requirement already satisfied: transformers==4.15.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (4.15.0)\r\n",
      "Requirement already satisfied: fairscale==0.4.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (0.4.4)\r\n",
      "Requirement already satisfied: pycocoevalcap in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.2)\r\n",
      "Collecting albumentations (from -r requirements.txt (line 5))\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4f/55/3c2ce84c108fc1d422afd6de153e4b0a3e6f96ecec4cb9afcf0284ce3538/albumentations-1.3.0-py3-none-any.whl (123 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from timm==0.4.12->-r requirements.txt (line 1)) (1.13.1)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from timm==0.4.12->-r requirements.txt (line 1)) (0.14.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (3.0.12)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (0.11.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (1.19.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (20.9)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (5.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (2023.5.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (2.24.0)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (0.0.53)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (0.10.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (4.64.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.15.0->-r requirements.txt (line 2)) (0.23)\r\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pycocoevalcap->-r requirements.txt (line 4)) (2.0.6)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from albumentations->-r requirements.txt (line 5)) (1.6.3)\r\n",
      "Collecting scikit-image>=0.16.1 (from albumentations->-r requirements.txt (line 5))\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2d/ba/63ce953b7d593bd493e80be158f2d9f82936582380aee0998315510633aa/scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting qudida>=0.0.4 (from albumentations->-r requirements.txt (line 5))\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f0/a1/a5f4bebaa31d109003909809d88aeb0d4b201463a9ea29308d9e4f9e7655/qudida-0.0.4-py3-none-any.whl (3.5 kB)\r\n",
      "Collecting opencv-python-headless>=4.1.1 (from albumentations->-r requirements.txt (line 5))\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3f/45/21fc904365f9cea3559e0192349bfe3ea2dce52672c1d9127c3b59711804/opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0->-r requirements.txt (line 2)) (4.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.15.0->-r requirements.txt (line 2)) (2.4.2)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pycocotools>=2.0.2->pycocoevalcap->-r requirements.txt (line 4)) (2.2.3)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations->-r requirements.txt (line 5)) (0.24.2)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 5)) (2.4)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 5)) (8.2.0)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 5)) (2.6.1)\r\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 5))\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d8/38/85ae5ed77598ca90558c17a2f79ddaba33173b31cf8d8f545d34d9134f0d/tifffile-2021.11.2-py3-none-any.whl (178 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1 (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 5))\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/56/4441877073d8a5266dbf7b04c7f3dc66f1149c8efb9323e0ef987a9bb1ce/PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.12->-r requirements.txt (line 1)) (11.7.99)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.12->-r requirements.txt (line 1)) (8.5.0.96)\r\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.4->timm==0.4.12->-r requirements.txt (line 1))\r\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ce/41/fdeb62b5437996e841d83d7d2714ca75b886547ee8017ee2fe6ea409d983/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.12->-r requirements.txt (line 1)) (11.7.99)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->timm==0.4.12->-r requirements.txt (line 1)) (56.2.0)\r\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->timm==0.4.12->-r requirements.txt (line 1)) (0.36.2)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->transformers==4.15.0->-r requirements.txt (line 2)) (3.8.1)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.15.0->-r requirements.txt (line 2)) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.15.0->-r requirements.txt (line 2)) (2.8)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.15.0->-r requirements.txt (line 2)) (1.25.11)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.15.0->-r requirements.txt (line 2)) (2019.9.11)\r\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.15.0->-r requirements.txt (line 2)) (1.15.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.15.0->-r requirements.txt (line 2)) (8.0.4)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.15.0->-r requirements.txt (line 2)) (0.14.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r requirements.txt (line 4)) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r requirements.txt (line 4)) (2.8.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r requirements.txt (line 4)) (2019.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r requirements.txt (line 4)) (1.1.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx>=2.2->scikit-image>=0.16.1->albumentations->-r requirements.txt (line 5)) (4.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r requirements.txt (line 5)) (2.1.0)\r\n",
      "Installing collected packages: tifffile, PyWavelets, opencv-python-headless, nvidia-cublas-cu11, scikit-image, qudida, albumentations\r\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] 权限不够: '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/cv2/config-3.py'\r\n",
      "Consider using the `--user` option or check the permissions.\r\n",
      "\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 安装工程运行的相关环境和依赖，\n",
    "# 代码主要基于blip和clip\n",
    "# 源码地址：https://github.com/salesforce/BLIP  &&  https://github.com/openai/CLIP\n",
    "!pip install  /home/aistudio/work/whl/pycocoevalcap-1.2-py3-none-any.whl\n",
    "!pip install  /home/aistudio/work/whl/torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!cd /home/aistudio && pwd && pip install -r requirements.txt\n",
    "\n",
    "!cd /home/aistudio/work/open_clip && pwd && pip install -r requirements.txt && make install\n",
    "!pip uninstall nvidia-cublas-cu11 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T10:15:38.088688Z",
     "iopub.status.busy": "2023-05-19T10:15:38.087525Z",
     "iopub.status.idle": "2023-05-19T10:22:24.071200Z",
     "shell.execute_reply": "2023-05-19T10:22:24.070208Z",
     "shell.execute_reply.started": "2023-05-19T10:15:38.088640Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: 'NoneType' object has no attribute 'shape' glfiujbncw.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' srpxdxpsrv.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' chpzftdygq.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' lzhwjbxsoz.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' uhgbxicbfn.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' taponjwfnf.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' oivusxfufn.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' njoytgkfbx.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' ydryqpzqrg.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' qvugvonuuc.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' lcjycorafq.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' penusitdqv.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' mtcwkmsahr.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' wrqibjvdar.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' whwsgtolln.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' abqljiurly.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' qwjaynrhjh.jpg\r\n",
      "libpng warning: iCCP: known incorrect sRGB profile\r\n",
      "warning: 'NoneType' object has no attribute 'shape' xsimfjlirf.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' cbzpwbctlb.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' kacsvsaniy.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' asomeqyoxl.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' xygfgyzslr.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' elpwmoxqqx.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' mmbvaricma.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' ayeyzdytvc.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' yccohcreim.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' qxuswdgwaz.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' tmanmuposm.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' cnezntoswr.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' lfbubflftr.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' xqqxxfxwwr.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' dxohwqpstj.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' zlfrimghso.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' npvkvbknar.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' mhjxdtibfw.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' kmosirnjwi.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' qbfhdkvrab.jpg\r\n",
      "warning: 'NoneType' object has no attribute 'shape' fwuwzobthj.jpg\r\n"
     ]
    }
   ],
   "source": [
    "# 数据处理  出现warning 可以忽略\n",
    "!cd /home/aistudio/work/open_clip && python3 data_preprocess_prompt_and_padding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-19T11:18:44.586040Z",
     "iopub.status.busy": "2023-05-19T11:18:44.585327Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/open_clip\r\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\r\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██| 5.07M/5.07M [00:37<00:00, 134kB/s]\r\n",
      "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
     ]
    }
   ],
   "source": [
    "# Track2 生成测试集结果文件, 生成文件保存在/home/aistudio/work/BLIP/result_json/infer_json.json\n",
    "!cd /home/aistudio/work/open_clip && pwd && sh infer_clip.sh\n",
    "!cd /home/aistudio/work/BLIP && pwd && sh infer.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 由于存储不够，在训练之前请使用rm -r /home/aistudio/data/data218773 将A榜提交的checkpoint删除（重启会自动恢复）\n",
    "## rm -r /home/aistudio/data/data218773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T10:36:33.302719Z",
     "iopub.status.busy": "2023-05-19T10:36:33.302402Z",
     "iopub.status.idle": "2023-05-19T10:36:39.423543Z",
     "shell.execute_reply": "2023-05-19T10:36:39.422469Z",
     "shell.execute_reply.started": "2023-05-19T10:36:33.302696Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/BLIP\r\n",
      "WARNING:__main__:\r\n",
      "*****************************************\r\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "*****************************************\r\n",
      "| distributed init (rank 2, word 4): env://\r\n",
      "| distributed init (rank 1, word 4): env://\r\n",
      "| distributed init (rank 3, word 4): env://\r\n",
      "| distributed init (rank 0, word 4): env://\r\n",
      "^C\r\n",
      "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\r\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 14464 closing signal SIGINT\r\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 14465 closing signal SIGINT\r\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 14466 closing signal SIGINT\r\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 14467 closing signal SIGINT\r\n"
     ]
    }
   ],
   "source": [
    "# Track2 blip模型训练, 训练完成后checkpoint保存在/home/aistudio/work/BLIP/output/cvpr23_finetune中，\n",
    "# 在推理时需替换/home/aistudio/work/BLIP/cvpr23_infer.py中的pretrained路径\n",
    "!cd /home/aistudio/work/BLIP && pwd && sh blip_train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Track2 clip模型训练，默认选择最后一个epoch，即第2个epoch。或者根据测试集测试结果，选择在测试级上最高的模型。\n",
    "!cd /home/aistudio/work/open_clip && pwd && sh clip_train.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
